{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "((X_train, y_train), (X_test, y_test)) = mnist.load_data()\n",
    " \n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ba06f15668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba069950b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBIAAAG9CAYAAACoKlVaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba06a6db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "print(y_train[0:10])\n",
    "\n",
    "figures, axes = plt.subplots(nrows=2, ncols=5)\n",
    "figures.set_size_inches(18, 8)\n",
    "\n",
    "axes[0][0].matshow(X_train[0])\n",
    "axes[0][1].matshow(X_train[1])\n",
    "axes[0][2].matshow(X_train[2])\n",
    "axes[0][3].matshow(X_train[3])\n",
    "axes[0][4].matshow(X_train[4])\n",
    "axes[1][0].matshow(X_train[5])\n",
    "axes[1][1].matshow(X_train[6])\n",
    "axes[1][2].matshow(X_train[7])\n",
    "axes[1][3].matshow(X_train[8])\n",
    "axes[1][4].matshow(X_train[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 28 * 28)\n",
    "X_test = X_test.reshape(10000, 28 * 28)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# One hot encoding을 합니다.\n",
    "# np.eye(10)[y_train]과 동일합니다.\n",
    "y_train_hot = to_categorical(y_train)\n",
    "\n",
    "# np.eye(10)[y_test]와 동일합니다.\n",
    "y_test_hot = to_categorical(y_test)\n",
    "\n",
    "print(y_train_hot.shape, y_test_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\AI\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\AI\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10,\n",
    "                kernel_initializer=RandomUniform(minval=0.0, maxval=0.001),\n",
    "                input_shape=(28 * 28,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "optimizers = SGD(lr=0.00001)\n",
    "model.compile(optimizer=optimizers,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s - loss: 2.3007 - acc: 0.1833 - val_loss: 2.2730 - val_acc: 0.1721\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s - loss: 1.7483 - acc: 0.1255 - val_loss: 1.0430 - val_acc: 0.1134\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s - loss: 1.0242 - acc: 0.1142 - val_loss: 0.9978 - val_acc: 0.1162\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.9995 - acc: 0.1177 - val_loss: 0.9818 - val_acc: 0.1193\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.9884 - acc: 0.1222 - val_loss: 0.9823 - val_acc: 0.1273\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.9819 - acc: 0.1276 - val_loss: 0.9854 - val_acc: 0.1263\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.9761 - acc: 0.1347 - val_loss: 0.9743 - val_acc: 0.1293\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.9718 - acc: 0.1420 - val_loss: 0.9964 - val_acc: 0.1436\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.9690 - acc: 0.1552 - val_loss: 0.9847 - val_acc: 0.1568\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.9658 - acc: 0.1774 - val_loss: 0.9757 - val_acc: 0.2060\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.5779 - acc: 0.6691 - val_loss: 0.3404 - val_acc: 0.9087\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3302 - acc: 0.9079 - val_loss: 0.3288 - val_acc: 0.9117\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3180 - acc: 0.9114 - val_loss: 0.3495 - val_acc: 0.9047\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3124 - acc: 0.9134 - val_loss: 0.3395 - val_acc: 0.9055\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3070 - acc: 0.9140 - val_loss: 0.3136 - val_acc: 0.9142\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.3016 - acc: 0.9152 - val_loss: 0.3126 - val_acc: 0.9186\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.2986 - acc: 0.9163 - val_loss: 0.3198 - val_acc: 0.9175\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.2980 - acc: 0.9163 - val_loss: 0.3214 - val_acc: 0.9145\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.2956 - acc: 0.9169 - val_loss: 0.3113 - val_acc: 0.9178\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s - loss: 0.2949 - acc: 0.9174 - val_loss: 0.3197 - val_acc: 0.9139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba02dce6a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          y_train_hot,\n",
    "          epochs=20,\n",
    "          validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.913900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  predict\n",
       "0       7        7\n",
       "1       2        2\n",
       "2       1        1\n",
       "3       0        0\n",
       "4       4        4\n",
       "5       1        1\n",
       "6       4        4\n",
       "7       9        9\n",
       "8       5        6\n",
       "9       9        9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "result = pd.DataFrame({'actual': y_test, 'predict': predictions})\n",
    "\n",
    "accuracy = (result['actual'] == result['predict']).mean()\n",
    "print(\"Accuracy = {0:.6f}\".format(accuracy))\n",
    "      \n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1000,\n",
    "                kernel_initializer=RandomUniform(minval=-0.058, maxval=0.058),\n",
    "                input_shape=(28 * 28,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(units=10,\n",
    "                kernel_initializer=RandomUniform(minval=-0.077, maxval=0.077)))\n",
    "\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "optimizers = SGD(lr=0.0001)\n",
    "model.compile(optimizer=optimizers,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 15s - loss: 2.1610 - acc: 0.2403 - val_loss: 2.0011 - val_acc: 0.4253\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 14s - loss: 1.8303 - acc: 0.5270 - val_loss: 1.6116 - val_acc: 0.6499\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 14s - loss: 1.4330 - acc: 0.6865 - val_loss: 1.2356 - val_acc: 0.7538\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 14s - loss: 1.1249 - acc: 0.7665 - val_loss: 0.9921 - val_acc: 0.8031\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 14s - loss: 0.9302 - acc: 0.8084 - val_loss: 0.8421 - val_acc: 0.8273\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 14s - loss: 0.8049 - acc: 0.8327 - val_loss: 0.7425 - val_acc: 0.8464\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 14s - loss: 0.7185 - acc: 0.8492 - val_loss: 0.6719 - val_acc: 0.8577\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.6552 - acc: 0.8612 - val_loss: 0.6193 - val_acc: 0.8668\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 12s - loss: 0.6068 - acc: 0.8689 - val_loss: 0.5787 - val_acc: 0.8724\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.5685 - acc: 0.8750 - val_loss: 0.5460 - val_acc: 0.8765\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.5372 - acc: 0.8806 - val_loss: 0.5190 - val_acc: 0.8812\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.5110 - acc: 0.8856 - val_loss: 0.4971 - val_acc: 0.8841\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.4887 - acc: 0.8894 - val_loss: 0.4780 - val_acc: 0.8877\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.4695 - acc: 0.8935 - val_loss: 0.4616 - val_acc: 0.8902\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.4527 - acc: 0.8969 - val_loss: 0.4473 - val_acc: 0.8936\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.4378 - acc: 0.8994 - val_loss: 0.4347 - val_acc: 0.8955\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.4246 - acc: 0.9022 - val_loss: 0.4235 - val_acc: 0.8988\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.4126 - acc: 0.9046 - val_loss: 0.4137 - val_acc: 0.8996\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.4017 - acc: 0.9065 - val_loss: 0.4046 - val_acc: 0.9018\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.3917 - acc: 0.9083 - val_loss: 0.3965 - val_acc: 0.9032\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.3826 - acc: 0.9100 - val_loss: 0.3889 - val_acc: 0.9064\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.3742 - acc: 0.9117 - val_loss: 0.3821 - val_acc: 0.9071\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 15s - loss: 0.3664 - acc: 0.9132 - val_loss: 0.3759 - val_acc: 0.9080\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 14s - loss: 0.3591 - acc: 0.9145 - val_loss: 0.3701 - val_acc: 0.9092\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 15s - loss: 0.3523 - acc: 0.9162 - val_loss: 0.3646 - val_acc: 0.9098\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 15s - loss: 0.3459 - acc: 0.9174 - val_loss: 0.3595 - val_acc: 0.9103\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 17s - loss: 0.3399 - acc: 0.9186 - val_loss: 0.3547 - val_acc: 0.9113\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.3342 - acc: 0.9197 - val_loss: 0.3502 - val_acc: 0.9118\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.3289 - acc: 0.9210 - val_loss: 0.3461 - val_acc: 0.9128\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.3238 - acc: 0.9221 - val_loss: 0.3421 - val_acc: 0.9132\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 17s - loss: 0.3190 - acc: 0.9230 - val_loss: 0.3383 - val_acc: 0.9140\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 15s - loss: 0.3145 - acc: 0.9240 - val_loss: 0.3349 - val_acc: 0.9142\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 15s - loss: 0.3101 - acc: 0.9250 - val_loss: 0.3312 - val_acc: 0.9153\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 16s - loss: 0.3060 - acc: 0.9260 - val_loss: 0.3282 - val_acc: 0.9153\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.3020 - acc: 0.9273 - val_loss: 0.3252 - val_acc: 0.9155\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2982 - acc: 0.9280 - val_loss: 0.3222 - val_acc: 0.9157\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2946 - acc: 0.9286 - val_loss: 0.3194 - val_acc: 0.9162\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.2911 - acc: 0.9297 - val_loss: 0.3167 - val_acc: 0.9171\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 17s - loss: 0.2878 - acc: 0.9302 - val_loss: 0.3140 - val_acc: 0.9174\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 16s - loss: 0.2845 - acc: 0.9310 - val_loss: 0.3118 - val_acc: 0.9184\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 16s - loss: 0.2814 - acc: 0.9315 - val_loss: 0.3093 - val_acc: 0.9187\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 15s - loss: 0.2784 - acc: 0.9323 - val_loss: 0.3070 - val_acc: 0.9191\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 15s - loss: 0.2755 - acc: 0.9331 - val_loss: 0.3048 - val_acc: 0.9199\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 14s - loss: 0.2727 - acc: 0.9340 - val_loss: 0.3027 - val_acc: 0.9204\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.2700 - acc: 0.9346 - val_loss: 0.3008 - val_acc: 0.9201\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 13s - loss: 0.2674 - acc: 0.9352 - val_loss: 0.2988 - val_acc: 0.9205\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 15s - loss: 0.2648 - acc: 0.9360 - val_loss: 0.2969 - val_acc: 0.9218\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 15s - loss: 0.2624 - acc: 0.9364 - val_loss: 0.2952 - val_acc: 0.9215\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 16s - loss: 0.2600 - acc: 0.9371 - val_loss: 0.2934 - val_acc: 0.9223\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2576 - acc: 0.9376 - val_loss: 0.2918 - val_acc: 0.9227\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 16s - loss: 0.2554 - acc: 0.9379 - val_loss: 0.2901 - val_acc: 0.9224\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 17s - loss: 0.2532 - acc: 0.9384 - val_loss: 0.2884 - val_acc: 0.9229\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2510 - acc: 0.9391 - val_loss: 0.2870 - val_acc: 0.9230\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.2490 - acc: 0.9396 - val_loss: 0.2854 - val_acc: 0.9228\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 17s - loss: 0.2469 - acc: 0.9405 - val_loss: 0.2839 - val_acc: 0.9236\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 15s - loss: 0.2449 - acc: 0.9409 - val_loss: 0.2825 - val_acc: 0.9230\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 17s - loss: 0.2430 - acc: 0.9411 - val_loss: 0.2812 - val_acc: 0.9234\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.2411 - acc: 0.9415 - val_loss: 0.2798 - val_acc: 0.9242\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 21s - loss: 0.2393 - acc: 0.9421 - val_loss: 0.2786 - val_acc: 0.9241\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 20s - loss: 0.2375 - acc: 0.9426 - val_loss: 0.2773 - val_acc: 0.9238\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.2357 - acc: 0.9428 - val_loss: 0.2761 - val_acc: 0.9244\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.2340 - acc: 0.9434 - val_loss: 0.2748 - val_acc: 0.9249\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 18s - loss: 0.2323 - acc: 0.9438 - val_loss: 0.2737 - val_acc: 0.9248\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2306 - acc: 0.9443 - val_loss: 0.2725 - val_acc: 0.9251\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2290 - acc: 0.9446 - val_loss: 0.2714 - val_acc: 0.9252\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2274 - acc: 0.9450 - val_loss: 0.2703 - val_acc: 0.9255\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2259 - acc: 0.9453 - val_loss: 0.2694 - val_acc: 0.9253\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2244 - acc: 0.9457 - val_loss: 0.2682 - val_acc: 0.9257\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2229 - acc: 0.9459 - val_loss: 0.2673 - val_acc: 0.9260\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 17s - loss: 0.2214 - acc: 0.9464 - val_loss: 0.2663 - val_acc: 0.9258\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2200 - acc: 0.9468 - val_loss: 0.2653 - val_acc: 0.9264\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2186 - acc: 0.9469 - val_loss: 0.2644 - val_acc: 0.9263\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.2172 - acc: 0.9475 - val_loss: 0.2636 - val_acc: 0.9262\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.2158 - acc: 0.9478 - val_loss: 0.2627 - val_acc: 0.9263\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2145 - acc: 0.9481 - val_loss: 0.2619 - val_acc: 0.9268\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2132 - acc: 0.9483 - val_loss: 0.2610 - val_acc: 0.9268\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2119 - acc: 0.9487 - val_loss: 0.2600 - val_acc: 0.9267\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2107 - acc: 0.9492 - val_loss: 0.2594 - val_acc: 0.9270\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2094 - acc: 0.9495 - val_loss: 0.2586 - val_acc: 0.9271\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2082 - acc: 0.9496 - val_loss: 0.2577 - val_acc: 0.9270\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2070 - acc: 0.9501 - val_loss: 0.2570 - val_acc: 0.9271\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2058 - acc: 0.9503 - val_loss: 0.2562 - val_acc: 0.9272\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2047 - acc: 0.9505 - val_loss: 0.2555 - val_acc: 0.9275\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2035 - acc: 0.9509 - val_loss: 0.2548 - val_acc: 0.9279\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2024 - acc: 0.9512 - val_loss: 0.2541 - val_acc: 0.9279\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.2013 - acc: 0.9514 - val_loss: 0.2534 - val_acc: 0.9283\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.2002 - acc: 0.9516 - val_loss: 0.2526 - val_acc: 0.9284\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.1991 - acc: 0.9519 - val_loss: 0.2520 - val_acc: 0.9282\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.1981 - acc: 0.9521 - val_loss: 0.2513 - val_acc: 0.9288\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.1970 - acc: 0.9523 - val_loss: 0.2507 - val_acc: 0.9287\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.1960 - acc: 0.9526 - val_loss: 0.2500 - val_acc: 0.9292\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.1950 - acc: 0.9530 - val_loss: 0.2494 - val_acc: 0.9292\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.1940 - acc: 0.9532 - val_loss: 0.2487 - val_acc: 0.9292\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.1930 - acc: 0.9535 - val_loss: 0.2481 - val_acc: 0.9294\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.1921 - acc: 0.9536 - val_loss: 0.2474 - val_acc: 0.9293\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.1911 - acc: 0.9538 - val_loss: 0.2468 - val_acc: 0.9298\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.1901 - acc: 0.9543 - val_loss: 0.2463 - val_acc: 0.9295\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.1892 - acc: 0.9544 - val_loss: 0.2457 - val_acc: 0.9297\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 18s - loss: 0.1883 - acc: 0.9548 - val_loss: 0.2451 - val_acc: 0.9299\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 19s - loss: 0.1874 - acc: 0.9552 - val_loss: 0.2445 - val_acc: 0.9304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba07ee0780>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          y_train_hot,\n",
    "          epochs=100,\n",
    "          validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.930400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  predict\n",
       "0       7        7\n",
       "1       2        2\n",
       "2       1        1\n",
       "3       0        0\n",
       "4       4        4\n",
       "5       1        1\n",
       "6       4        4\n",
       "7       9        9\n",
       "8       5        6\n",
       "9       9        9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "result = pd.DataFrame({'actual': y_test, 'predict': predictions})\n",
    "\n",
    "accuracy = (result['actual'] == result['predict']).mean()\n",
    "print(\"Accuracy = {0:.6f}\".format(accuracy))\n",
    "      \n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
